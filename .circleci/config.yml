version: 2.1
orbs:
  slack: circleci/slack@4.1
executors:
  node:
    docker:
      - image: circleci/node:13.8.0
  python:
    docker:
      - image: python:3.9.0-alpine
  aws:
    docker:
      - image: amazon/aws-cli
commands:
    install_awscli:
      description: Install AWS CLI v2
      steps:
        - run:
            name: Install AWS CLI v2
            command: |
              apt-get update && apt-get install curl -y
              curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
              unzip awscliv2.zip
              sudo ./aws/install
    install_ansible:
      description: Install Ansible
      steps:
        - run:
            name: Install Ansible
            command: |
              sudo apt update
              sudo apt install software-properties-common -y
              sudo add-apt-repository --yes --update ppa:ansible/ansible
              sudo apt install ansible -y
    install_nodejs:
      description: Install Node.js 13
      steps:
        - run:
            name: Install Node.js 13
            command: |
              apt-get update && apt-get install curl -y
              # Install Node.js LTS version as our base Node.js version
              curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -
              sudo apt install -y nodejs
              # Use n version manager to use Node.js v13.8.0
              sudo npm install --global n
              sudo n 13.8.0
    destroy-environment:
        description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
        parameters:
            workflow_id:
                type: string
                
        steps:
            - run:
                  name: Destroy environments
                  when: on_fail
                  command: |
                      echo "Destroying environment: << parameters.workflow_id >> "
                      aws cloudformation delete-stack --stack-name udapeople-backend-<< parameters.workflow_id >>
                      aws s3 rm s3://udapeople-<<parameters.workflow_id>> --recursive
                      aws cloudformation delete-stack --stack-name udapeople-frontend-<< parameters.workflow_id >>
    
    revert-migrations:
        description: Revert the last migration
        parameters:
            workflow_id:
                type: string      
        steps:
            - run:
                  name: Revert migrations
                  when: on_fail
                  command: |
                      SUCCESS=$(curl --insecure  https://kvdb.io/RP74xht2bKTgWuAxoRb2H5/migration_<< parameters.workflow_id >>)
                        # Logic for reverting the database state
                      if (( $SUCCESS == 1 ));
                      then
                          cd ~/project/backend
                          npm install
                          npm run migration:revert 
                      else
                          echo "zero migration."
                      fi

jobs:
    build-frontend:
        docker:
            - image: circleci/node:13.8.0
        steps:
            - checkout
            - restore_cache:
                  keys: [frontend-build]
            - run:
                  name: Install  dependencies and build frontend
                  command: |
                    cd frontend 
                    npm install
                    npm run build 
            - save_cache:
                  paths: [frontend/node_modules]
                  key: frontend-build

    build-backend:
        docker:
            - image: circleci/node:13.8.0
        steps:
            - checkout
            - restore_cache:
                  keys: [backend-build]
            - run:
                  name: Install dependencies and build backend
                  command: |
                    cd backend 
                    npm install
                    npm run build
            - save_cache:
                  paths: [backend/node_modules]
                  key: backend-build
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - project/backend/dist

    test-frontend:
        docker:
            - image: circleci/node:13.8.0
        steps:
            - checkout
            - restore_cache:
                  keys: [frontend-build]
            - run:
                  name: Install dependencies and test frontend
                  command: |
                    cd frontend 
                    npm install
                    npm run test 

    test-backend:
        docker:
            - image: circleci/node:13.8.0
        steps:
            - checkout
            - restore_cache:
                  keys: [backend-build]
            - run:
                  name: Install dependencies and test backend 
                  command: |
                    cd backend
                    npm install
                    npm run test 
                  environment:
                      NODE_OPTIONS: --max_old_space_size=8192

    scan-frontend:
        docker:
            - image: circleci/node:13.8.0
        steps:
            - checkout
            - restore_cache:
                  keys: [frontend-build]
            - run:
                  name: Install dependencies and scan frontend
                  command: |
                    cd frontend 
                    npm install
                    npm audit fix --audit-level=critical --force
                    npm audit fix  --force
                    npm audit --audit-level=critical 

    scan-backend:
        docker:
            - image: circleci/node:13.8.0
        steps:
            - checkout
            - restore_cache:
                  keys: [backend-build]
            - run:
                  name: Install dependencies and scan backend
                  command: |
                    cd backend 
                    npm install
                    npm audit fix --audit-level=critical --force
                    npm audit fix  --force
                    npm audit --audit-level=critical 

    deploy-infrastructure:
        docker:
            - image: python:3.7-alpine
        steps:
            - checkout
            - run:
                  name: Install dependencies
                  command: |
                      apk add --update tar gzip curl
                      pip install awscli
            - run:     
                  name: Ensure backend infrastructure exists
                  command: |
                      aws cloudformation deploy \
                      --template-file .circleci/files/backend.yml \
                      --stack-name "udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7}" \
                      --parameter-overrides ID=${CIRCLE_WORKFLOW_ID:0:7} \
                      --tags project=udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}
            - run:
                  name: Ensure frontend infrastructure exist
                  command: |
                      aws cloudformation deploy \
                      --template-file .circleci/files/frontend.yml \
                      --stack-name "udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}" \
                      --parameter-overrides ID=${CIRCLE_WORKFLOW_ID:0:7}  \
                      --tags project=udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7}
            - run:
                  name: Add backend ip to ansible inventory
                  command: |
                        aws ec2 describe-instances \
                        --filters "Name=tag:project,Values=udapeople" \
                        --query 'Reservations[*].Instances[*].PublicIpAddress' \
                        --output text >> .circleci/ansible/inventory.txt
            - persist_to_workspace:
                  root: ~/
                  paths:
                      - project/.circleci/ansible/inventory.txt
            - destroy-environment:
                  workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}

    configure-infrastructure:
        docker:
            - image: python:3.7-alpine
              environment:
                  ANSIBLE_HOST_KEY_CHECKING: "no"
        steps:
            - checkout
            - run:
                  name: Install config dependencies
                  command: |
                      apk add --update tar gzip curl nodejs npm ansible zip
                      pip install awscli
            - add_ssh_keys:
                  fingerprints:
                      ["f4:19:68:91:56:8f:b5:36:30:90:12:d9:31:37:fd:7d"]
            - attach_workspace:
                  at: ~/
            - run:
                  name: Configure Server
                  command: |
                      cd .circleci/ansible
                      cat inventory.txt
                      ansible-playbook -i inventory.txt configure-server.yml
            - destroy-environment:
                  workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}

    run-migrations:
        docker:
            - image: circleci/node:13.8.0
        steps:
            - checkout
            - restore_cache:
                keys: [backend-build]
            - run:
                  name: Install dependencies
                  command: |
                      curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                      unzip awscliv2.zip
                      sudo ./aws/install
                      echo aws --version
            - run:
                  name: Run migrations
                  command: |
                      cd backend
                      sudo npm install
                      sudo npm i || cat /root/.npm/_logs/2022-*debug.log
                      sudo npm run migrations >> migration_status || sudo cat migration_status
            - run:
                  name: Send migration info to kvdb.io 
                  command: |   
                      if grep -q "has been executed successfully." ~/project/backend/migrations_dump.txt
                      then
                          curl --insecure https://kvdb.io/RP74xht2bKTgWuAxoRb2H5/migration_${CIRCLE_WORKFLOW_ID:0:7}  -d '1'
                          echo "migration complete -------"
                      else 
                          echo "no migration happened"
                        
                      fi
            - destroy-environment:
                  workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}
            - revert-migrations:
                  workflow_id: ${CIRCLE_WORKFLOW_ID:0:7}

    deploy-frontend:
        docker:
            - image: python:3.7-alpine
        steps:
            - checkout
            #- install_awscli
            #- install_nodejs
            - run:
                  name: Install dependencies
                  command: |
                        apk add --update tar gzip curl nodejs npm zip
                        pip install awscli
                        apt-get update && apt-get install curl -y
                        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                        unzip awscliv2.zip
                        ./aws/install
                        apt install software-properties-common -y
                        add-apt-repository --yes --update ppa:ansible/ansible
                        apt install ansible -y
            - attach_workspace:
                  at: ~/     

            - run:
                  name: Get backend url
                  command: |
                        export BACKEND_IP=$(aws ec2 describe-instances \
                         --filters "Name=tag:project,Values=udapeople" \
                         --query 'Reservations[*].Instances[*].PublicIpAddress' \
                         --output text)
                        export API_URL="http://${BACKEND_IP}:3030"
                        echo "${API_URL}"     
                        echo API_URL="http://${BACKEND_IP}:3030" >> frontend/.env
                        cat frontend/.env   
            - run:
                  name: Build and Deploy frontend objects
                  command: |
                       cd frontend
                       npm run build
                       tar -czvf artifact-"${CIRCLE_WORKFLOW_ID:0:7}".tar.gz dist
                       aws s3 cp dist s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
            - destroy-environment:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
            - revert-migrations:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

    deploy-backend:
        docker:
            - image: python:3.7-alpine3.11
        steps:
            - checkout
            - add_ssh_keys:
                fingerprints: ["f4:19:68:91:56:8f:b5:36:30:90:12:d9:31:37:fd:7d"]
            - attach_workspace:
                at: .          
            - run:
                  name: Install dependencies
                  working_directory: /tmp
                  command: |
                      apk add --update ansible curl rsync openssh nodejs npm
                      ansible --version
                      pip install awscli
                      aws --version
           
            - run:
                  name: Package, Deploy Backend and configure prometheus service discovery
                  command: |
                      cd backend
                      npm i
                      npm run build 
                      cd ..
                      tar -C backend -czvf artifact.tar.gz .
                      mkdir -p ~/project/.circleci/ansible/roles/deploy/files/
                      mv artifact.tar.gz .circleci/ansible/roles/deploy/files/artifact.tar.gz
                      cd .circleci/ansible
                      echo "contents of the inventory.txt file is ------$(tail -i inventory.txt)"
                      cat inventory.txt
                      export ANSIBLE_HOST_KEY_CHECKING=False
                      ansible-playbook -i inventory.txt deploy-backend.yml
                     
            - destroy-environment:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
            - revert-migrations:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

    smoke-test:
        docker:
            - image: python:3.7-alpine
        steps:
            - checkout
            - run:
                  name: Install dependencies
                  command: |
                      apk add --update tar gzip curl
                      pip install awscli
            - attach_workspace:
                  at: ~/
            - run:
                  name: Smoke Test frontend app
                  command: |
                      URL="http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website-us-east-1.amazonaws.com/#/employees"            
                      echo ${URL} 
                      if curl -s ${URL} | grep "Welcome"
                      then
                        # Change this to 0 after the job fails
                          return 0
                      else
                          return 1
                      fi
            - run:
                  name: Get backend url
                  command: |
                      export BACKEND_IP=$(aws ec2 describe-instances \
                        --filters "Name=tag:project,Values=udapeople" \
                        --query 'Reservations[*].Instances[*].PublicIpAddress' \
                        --output text)
                      export API_URL="http://${BACKEND_IP}:3030"
                      echo "${API_URL}"
                      if curl "${API_URL}/api/status" | grep "ok"
                      then
                          return 0
                      else
                          return 1
                      fi
            
            
            - destroy-environment:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
            - revert-migrations:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

    cloudfront-update:
        docker:
            - image: python:3.7-alpine
        steps:
            - checkout
            - run:
                  name: Install dependencies
                  command: |
                      apk add --update curl
                      pip install awscli
            - run:
                  name: save old workflow ID to kvdb.io
                  command: |
                       export OLD_WORKFLOW_ID=$(aws cloudformation \
                            list-exports --query "Exports[?Name==\`WorkflowID\`].Value" \
                            --no-paginate --output text)
                        echo "old workflow ID is: $OLD_WORKFLOW_ID"
                       curl -k https://kvdb.io/RP74xht2bKTgWuAxoRb2H5/OLD_WORKFLOW_ID -d "${OLD_WORKFLOW_ID}"
            - run:
                  name: Update Cloudfront 
                  command:  |
                       aws cloudformation deploy \
                            --template-file .circleci/files/cloudfront.yml \
                            --stack-name InitialStack \
                            --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:7}" \
                            --tags project=udapeople
                
            - destroy-environment:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
            - revert-migrations:
                  workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"

    cleanup:
        docker:
            - image: python:3.7-alpine
        steps:
            - checkout
            - run:
                name: Install dependencies
                command: |
                    apk add --update curl bash
                    pip install awscli
                    pip install nodejs 

            - run:
                  name: Remove old stacks and files
                  shell: /bin/bash
                  command: |
                      export STACKS=$(aws cloudformation list-stacks \
                        --query "StackSummaries[*].StackName" \
                        --stack-status-filter CREATE_COMPLETE --no-paginate --output text) 
                      echo Stack names: "${STACKS[@]}"

                      export OldWorkflowID=$(curl --insecure https://kvdb.io/RP74xht2bKTgWuAxoRb2H5/OLD_WORKFLOW_ID)
                      echo Old Workflow ID: $OldWorkflowID 

                      if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
                      then
                        aws s3 rm "s3://udapeople-${OldWorkflowID}" --recursive
                        aws cloudformation delete-stack --stack-name "udapeople-backend-${OldWorkflowID}"
                        aws cloudformation delete-stack --stack-name "udapeople-frontend-${OldWorkflowID}"
                      fi
        
                      

                      
workflows:
    default:
        jobs:
            - build-frontend
            - build-backend
            - test-frontend:
                  requires: [build-frontend]
            - test-backend:
                  requires: [build-backend]
            - scan-frontend:
                  requires: [build-frontend]
            - scan-backend:
                  requires: [build-backend]
            - deploy-infrastructure:
                requires: [test-frontend, test-backend, scan-frontend, scan-backend]
                filters:
                  branches:
                    only: [master]
    
            - configure-infrastructure:
                  requires: [deploy-infrastructure]
            - run-migrations:
                  requires: [configure-infrastructure]
            - deploy-frontend:
                  requires: [run-migrations]
            - deploy-backend:
                  requires: [run-migrations]
            - smoke-test:
                  requires: [deploy-backend, deploy-frontend]
            - cloudfront-update:
                  requires: [smoke-test]
            - cleanup:
                  requires: [cloudfront-update]